---
title: '"NOISE-ADDED" REGRESSION ANALYSIS'
author: "Stanley Sayianka"
date: "6/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
```


# SWEDISH AUTO INSURANCE ANALYSIS

For this first experimental analysis, I fetched the Swedish auto insurance dataset, which consists of only two variables:

- The number of claims

- Total payment for all the claims in Swedish Kronor for geographical zones in Sweden

Reference about the dataset can be found at: Swedish committee on Analysis of risk premium in motor insurance.

I split the dataset into a training set and a testing set as follows:

- Training set: 53 data points
- Testing set: 10 data points.

## DATA PREPARATION AND VISUALIZATION

```{r, prepviz}
# dir
setwd("C:/Users/stanley/Desktop/MISCELLANEOUS R/ml projects/regression/anujonthemove-auto-insurance-in-sweden/original")

# the combine knn lm model
source("C:/Users/stanley/Desktop/MISCELLANEOUS R/ml projects/Knn/knn classifier/combine knn_lm.R")

# libs
library(pacman)
p_load(dplyr, ggplot2, stringr, stringi, ModelMetrics, plotly)

# data
autodd <- read.csv("auto_insurance_sweden.csv", as.is=T)

# summary and str
names(autodd) <- c("claims_no", "total_payment")

# viz
ggplot(data=autodd)+
  geom_point(aes(claims_no, total_payment))+
  labs(title="CLAIMS NUMBER AND TOTAL PAYMENT",
       x="Number of claims",y="Total payment")+
  geom_smooth(aes(claims_no, total_payment), method="lm")


# splitting the data for training and testing
set.seed(29)
test <- sample(63, 10)
dd_train <- autodd[-test,]
dd_test <- autodd[test, ]

```

## MODEL BUILDING

```{r, modd}
# fitting the model
mod1 <- lm(total_payment~claims_no, 
           data=dd_train)
summary(mod1)
```

It can be seen that both the intercept and the claims number variable are significant in explaining the total payment on claims. The R squared value reported 0.8485 is higher implying that approximately 86% of the variation in total payments is accounted for by the model.

The mean squared and rooted mean squared metrics for the pure regression model are shown below:

```{r, metrics}

# using the fitted model to predict test
pred_payment <- predict(mod1, dd_test)

# error analysis
print(paste("The MSE is", mse(pred_payment, dd_test$total_payment)))
print(paste("The RMSE is", rmse(pred_payment, dd_test$total_payment)))
```

From now on, we shall treat this regression model as the baseline model, in order to analyze performance of the noise added models:

## NOISE ADDING

```{r, noi}
scaletest <- apply(dd_test, 2, scale)
scaletrain <- apply(dd_train, 2, scale)



# the noise adding, using 30 neighbours
ds <- combine_knnlm(train = scaletrain, 
                    test = scaletest, 
                    k=30)

# starting a loop for one to thirty
msevec <- vector()
noisepred <- vector()

for (k in 1:30)
{
  #print(paste("Running batch: ", k))
  
  for (i in 1:nrow(scaletest))
  {
    noisepred[i] <- pred_payment[i] + mean(mod1$residuals[ds[[i]][1:k]])
  }
  
  msevec[k] <- mse(dd_test$total_payment, noisepred)
}

md <- cbind(1:30, msevec) %>%
  as.data.frame()
colnames(md) <- c("Neighbor", "msevec")

p <- ggplot(data=md)+
  geom_line(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_point(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_hline(yintercept = mse(pred_payment, dd_test$total_payment),
             col="red", lwd=2)+
  labs(title="PERFORMANCE OF NOISE ADDED MODELS", 
       x="K parameter in Noise added models",
       y="Mean Squared Error",
       subtitle = "Red-The baseline model")
ggplotly(p)

```


# TERM LIFE ASSURANCE DATA

In this example, we examine the Survey of Consumer Finances (SCF), a
nationally representative sample that contains extensive information on assets, liabilities, income, and demographic characteristics of those sampled (potential U.S. customers). We study a random sample of 275 households with positive incomes that were interviewed in the 2004 survey that purchased term life insurance. We wish to accurately determine family characteristics that influence the amount of insurance purchased.


The data is split into the training and testing set as follows:

- Training set – Data for 225 households
- Testing set – Data for 50 households.

The variables of interest in our case are:

1. EDUCATION - Number of years of education of the survey respondent

2. INCOME - Annual income

3. NUMHH - Number of household members

4. FACE - Quantity of insurance is measured by the policy FACE.

## DATA PREPARATION

Since the variables of interest FACE and INCOME, are highly skewed, i applied a log tranformation in analysis, the plot describes the variables.

```{r, dp}
setwd("C:/Users/stanley/Desktop/MISCELLANEOUS R/research")

# data
termlife <- read.csv("TermLife.csv", as.is = T)
#glimpse(termlife)

# only choosing three variables to explain
# since distribution of FACE and INCOME is much skewed we conside their log

tl <- select(termlife, EDUCATION, NUMHH, INCOME, FACE)

#log transform
tl$FACE <- ifelse(tl$FACE == 0, yes = NA, no = tl$FACE)
tl <- na.omit(tl)

tl[, 3:4] <- apply(tl[, 3:4], 2, log)

# visualizations
#library(GGally)
#ggpairs(tl)
pairs(tl)

# splitting data into test and train
set.seed(29)
test <- sample(275, 50)
dd_train <- tl[-test,]
dd_test <- tl[test, ]
```

## MODEL BUILDING

```{r, MODBU}
# model
tl_mod <- lm(FACE~., data=dd_train)
summary(tl_mod)

```

The fitted model is shown above, where only 28% of the total variation in FACE value is explained by the model, although all the variables are significant. This low variability explained could be due to the few number of variables used in explaining the model.

The mean squared and rooted mean squared metrics for the pure regression model are shown below:

```{r, mm}

# using the fitted model to predict test
pred_face <- predict(tl_mod, dd_test)

# error analysis
print(paste("The MSE is", mse(pred_face, dd_test$FACE)))
print(paste("The RMSE is", rmse(pred_face, dd_test$FACE)))
```

From now on, we shall treat this regression model as the baseline model, in order to analyze performance of the noise added models:

## NOISE ADDING

I fitted a total of 30 noise added models, from the 1 neighbour noise-model to the 30 neighbor noise model, and their performance in terms of the MSE metric is visualized below in comparison to the baseline model

```{r, nm}
scaletest <- apply(dd_test, 2, scale)
scaletrain <- apply(dd_train, 2, scale)

# the noise adding, using 30 neighbours
ds <- combine_knnlm(train = scaletrain, 
                    test = scaletest, 
                    k=30)

# starting a loop for one to thirty
msevec <- vector()
noisepred <- vector()

for (k in 1:30)
{
  #print(paste("Running batch: ", k))
  
  for (i in 1:nrow(scaletest))
  {
    noisepred[i] <- pred_face[i] + mean(tl_mod$residuals[ds[[i]][1:k]])
  }
  
  msevec[k] <- mse(dd_test$FACE, noisepred)
}


md <- cbind(1:30, msevec) %>%
  as.data.frame()
colnames(md) <- c("Neighbor", "msevec")
p <- ggplot(data=md)+
  geom_line(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_point(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_hline(yintercept = mse(pred_face, dd_test$FACE),
             col="red")+
  labs(title="PERFORMANCE OF NOISE ADDED MODELS", 
       x="K parameter in Noise added models",
       y="Mean Squared Error",
       subtitle = "Red-The baseline model")
ggplotly(p)

```



As can be seen, the noise added models performed way better than the baseline regression model, one noise added model even performed 80% more better than the baseline model, indicating a higher level of accuracy of the noise added models.


# STOCK MARKET LIQUIDITY

An investor's decision to purchase a stock is generally made with a number of criteria in mind. First, investors usually look for a high expected return. A second criterion is the riskiness of a stock, which can be measured through the variability of the returns. Third, many investors are concerned with the length of time that they are committing their capital with the purchase of a security. Many income stocks, such as utilities, regularly return portions of capital investments in the form of dividends. Other stocks, particularly growth stocks, return nothing until the sale of the security. Thus, theaverage length of investment in a security is another criterion. Fourth, investors are concerned with the ability to sell the stock at any time convenient to the investor. We refer to this fourth criterion as the liquidity of the stock. The more liquid is the stock, the easier it is to sell. To measure the liquidity, in this study, we use the number of shares traded on an exchange over a specified period of time (called the VOLUME). We are interested in studying the relationship between the volume and other financial characteristics of a stock. 

We begin this analysis with 126 companies whose options were traded on December 3, 1984. The stock data were obtained from Francis Emory Fitch Inc. for the period from December 3, 1984, to February 28, 1985.

## DATA PREPARATION

Although the data had a lot more variables, the variables i chose include the following:

1. The three-month total trading volume (VOLUME, in millions of shares)

2. The three-month total number of transactions (NTRAN)

3. The average time between transactions (AVGT, measured in minutes)

I split the data into the training and testing set as follows:

Training set: Having 73 data points.
Testing set: Having 50 data points.

```{r, liqstart}
# dir
setwd("C:/Users/stanley/Desktop/MISCELLANEOUS R/research")

# data
liq <- read.csv("Liquidity.csv")
#glimpse(liq)

liq <- select(liq, VOLUME, NTRAN, AVGT)
#summary(liq)

# splitting data into training and testing
# splitting the data for training and testing
set.seed(29)
test <- sample(123, 50)
dd_train <- liq[-test,]
dd_test <- liq[test, ]
pairs(dd_train)
```

## MODEL BUILDING

The fitted regression model is shown below:

```{r, mdliq}
liqmod <- lm(VOLUME~NTRAN+AVGT, data=dd_train)
summary(liqmod)
```

From the output, the regression model accounts for 79% of the total variability in the response variable VOLUME.We also note that all the variables are significant.

The error metrics for the regression model is:

```{r, errmse}
# metric for baseline
# using the fitted model to predict test
pred_vol <- predict(liqmod, dd_test)

# error analysis
print(paste("The MSE is: ", mse(pred_vol, dd_test$VOLUME)))
print(paste("The RMSE is: ", rmse(pred_vol, dd_test$VOLUME)))
```


## NOISE ADDING

I fitted a total of 30 noise added models, and their comparison to the benchmark regression model is visualized below:

```{r, noisliq}

# Noise adding on regression
# NOISE ADDED MODELS ------------------------------------------------------

scaletest <- apply(dd_test, 2, scale)
scaletrain <- apply(dd_train, 2, scale)


# the noise adding, using 30 neighbours
ds <- combine_knnlm(train = scaletrain, 
                    test = scaletest, 
                    k=30)

# starting a loop for one to thirty
msevec <- vector()
noisepred <- vector()

for (k in 1:30)
{
  #print(paste("Running batch: ", k))
  
  for (i in 1:nrow(scaletest))
  {
    noisepred[i] <- pred_vol[i] + mean(liqmod$residuals[ds[[i]][1:k]])
  }
  
  msevec[k] <- mse(dd_test$VOLUME, noisepred)
}

md <- cbind(1:30, msevec) %>%
  as.data.frame()
colnames(md) <- c("Neighbor", "msevec")
p <- ggplot(data=md)+
  geom_line(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_point(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_hline(yintercept = mse(pred_vol, dd_test$VOLUME),
             col="red")+
  labs(title="PERFORMANCE OF NOISE ADDED MODELS", 
       x="K parameter in Noise added models",
       y="Mean Squared Error",
       subtitle = "Red-The baseline model")
ggplotly(p)
```


## INCORPORATING CATEGORICAL VARIABLES IN NOISE ADDING

In this experimental work, i show that we could still incorporate categorical variables in noise adding, by using one-hot encoding as shown below:

The categorical variables included in this analysis are:

Gender - Gender of the Survey respondent

MARSTAT - Marital status of the survey respondent

## DATA PREPARATION

The data with categorical variables is as shown below:


**Explain using the full report**

The full regression model is shown below:

```{r, catstart}
newtl <- select(termlife, SEDUCATION, TOTINCOME, MARSTAT, GENDER, FACE)
newtl$GENDER <- ifelse(newtl$GENDER == 1, "MALE", "FEMALE")
newtl$MARSTAT <- case_when(newtl$MARSTAT == 1 ~ "MARRIED",
                           newtl$MARSTAT == 2 ~ "PARTNER",
                           newtl$MARSTAT == 0 ~ "OTHER")
newtl$GENDER <- factor(newtl$GENDER)
newtl$MARSTAT <- factor(newtl$MARSTAT)

# splitting data into test and train
set.seed(29)
test <- sample(275, 50)
dd_train <- newtl[-test,]
dd_test <- newtl[test, ]

head(dd_train)
```

## MODEL BUILDING

The fitted regression model is as shown below:

```{r, MDLAST}
catmod <- lm(FACE~., data=dd_train)
summary(catmod)

catpred <- predict(catmod, dd_test)

```


The accuracy metrics of the regression model (we will refer this model to as the **baseline** model).

```{r, reportmetric}
print(paste("The MSE is: ", mse(catpred, dd_test$FACE)))
```

## NOISE ADDING

In order to get to noise added models, we will have to calculate distances, thus since it is impossible to calculate distances using categorical data, we employ techniques used in converting categorical data into numerical data e.g. one hot encoding, splitting, dummy coding e.t.c
In this particular case, i employ one hot encoding and the final dataset is shown below:

```{r, onehot}
source("C:/Users/stanley/Desktop/MISCELLANEOUS R/random/one hot encoding.R")

marstat <- onehot_swap(newtl$MARSTAT)
gender <- onehot_swap(newtl$GENDER)

final_tl <- cbind(newtl[, 1:2], newtl[, 5], marstat, gender)
colnames(final_tl) <- c("SEDUCATION", "TOTINCOME", "FACE", "MARRIED", 
                        "PARTNER", "OTHER", "MALE", "FEMALE")
set.seed(29)
test <- sample(275, 50)
dd_train <- final_tl[-test,]
dd_test <- final_tl[test, ]
head(dd_train)
```

In noise adding, i used thirty noise added models, ranging from the one neighbor model to the thirty neighbor model, and the performance is illustrated graphically, as shown below:

```{r, noiselast}
# noise adding by splitting the variables into dummy codes




# NOISE ADDED MODELS ------------------------------------------------------

scaletest <- apply(dd_test, 2, scale)
scaletrain <- apply(dd_train, 2, scale)


# the noise adding, using 30 neighbours
ds <- combine_knnlm(train = scaletrain, 
                    test = scaletest, 
                    k=30)

# starting a loop for one to thirty
msevec <- vector()
noisepred <- vector()

for (k in 1:30)
{
  #message(paste("Running batch: ", k))
  
  for (i in 1:nrow(scaletest))
  {
    noisepred[i] <- catpred[i] + mean(catmod$residuals[ds[[i]][1:k]])
  }
  
  msevec[k] <- mse(dd_test$FACE, noisepred)
}

md <- cbind(1:30, msevec) %>%
  as.data.frame()
colnames(md) <- c("Neighbor", "msevec")

p <- ggplot(data=md)+
  geom_line(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_point(aes(x=(Neighbor), y=msevec), col="blue")+
  geom_hline(yintercept = mse(pred_face, dd_test$FACE),
             col="red")+
  labs(title="PERFORMANCE OF NOISE ADDED MODELS", 
       x="K parameter in Noise added models",
       y="Mean Squared Error",
       subtitle = "Red-The baseline model")
ggplotly(p)

```






